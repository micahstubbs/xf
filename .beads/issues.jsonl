{"id":"xf-9rf","title":"xf: Full System Investigation, Review, and Performance Optimization","description":"Goal: Provide a self-contained, end-to-end plan to deeply understand the xf codebase, review code (including prior agent changes), identify and fix correctness/reliability issues, and run a rigorous performance investigation and optimization program.\n\nBackground/context:\n- Project root: /data/projects/xf\n- Key documents: AGENTS.md, README.md\n- Dataset provided for profiling: /data/projects/je_twitter_data/twitter-2026-01-09-b207c0562001e0a3e60faf1985feb13876dfbfe85c6831a1c73016daf6d4f2cc.zip (already extracted under /data/projects/je_twitter_data)\n- Perf workflow requirements: baseline metrics (p50/p95/p99, throughput, peak RSS), profile CPU/allocation/I/O, define equivalence oracles, rank opportunities by (Impact x Confidence)/Effort, apply minimal diffs with proof sketches, add regression guardrails.\n\nOutcome:\n- A structured set of tasks/subtasks with dependencies and detailed instructions so future work is self-contained and does not require the original plan document.\n\nNotes/constraints to preserve:\n- Follow AGENTS.md instructions (no file deletion, use apply_patch for edits, etc.).\n- Any optimization must preserve outputs for identical inputs (explicit proof sketch required).\n- Use minimal diffs: one performance lever per change, no unrelated refactors.\n- Add rollback guidance if risk exists.\n","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-10T02:23:41.616748361-05:00","created_by":"ubuntu","updated_at":"2026-01-10T02:23:41.616748361-05:00"}
{"id":"xf-9rf.1","title":"Read AGENTS.md + README and capture constraints","description":"Goal:\n- Re-read AGENTS.md and README.md in full and summarize all constraints, workflows, and project goals in a durable form.\n\nWhy:\n- All subsequent investigation, fixes, and performance work must comply with AGENTS.md instructions (e.g., no file deletion, apply_patch usage).\n\nSteps:\n1) Read /data/projects/xf/AGENTS.md carefully (end-to-end). Extract: editing constraints, testing expectations, prohibited actions, perf methodology, and any doc references to best practices.\n2) Read /data/projects/xf/README.md carefully. Extract: project purpose, build/run commands, data formats, expected usage.\n3) Record a concise summary in a working note (or issue comment) that can be referenced without re-opening the source docs.\n\nAcceptance:\n- A clear summary that enumerates all operational constraints and expected workflows.\n- Any referenced best-practice guides or doc links are listed for later lookup.\n","notes":"Summary (AGENTS.md + README):\n- Hard safety rules: never delete files; avoid destructive commands (git reset --hard, rm -rf, git clean -fd) unless user explicitly provides exact command and confirms irreversible consequences. Use safe alternatives first. Document any approved destructive action verbatim.\n- Editing discipline: no script-based code changes; modify files manually; no file proliferation (no *_v2.* style files). Use apply_patch for edits; Cargo-only toolchain; Rust 2024 nightly; unsafe forbidden; use explicit dependency versions.\n- Testing/quality gates required after substantive changes: cargo check --all-targets, cargo clippy --all-targets -- -D warnings, cargo fmt --check; run cargo test and focused tests.\n- Project semantics: xf indexes local X archive data; privacy-first (no network in core runtime); parse JS-wrapped JSON window.YTD.*; Tantivy primary search; SQLite FTS5 fallback; preserve metadata (IDs/timestamps/counts) exactly; CLI flags must be truthful; JSON output shape must remain stable.\n- README highlights: CLI provides index/search commands; supports types filters, offsets/limits, output formats (json/csv/compact); data archive layout includes data/*.js and assets/; parsing strips JS prefix; storage in SQLite + Tantivy; env vars XF_DB/XF_INDEX override storage; default storage paths by OS; performance targets and benches documented; build/test via cargo; installation via script or cargo nightly.\n","status":"closed","priority":2,"issue_type":"task","assignee":"ubuntu","created_at":"2026-01-10T02:24:03.88540847-05:00","created_by":"ubuntu","updated_at":"2026-01-10T02:25:28.26120732-05:00","closed_at":"2026-01-10T02:25:28.261214513-05:00","dependencies":[{"issue_id":"xf-9rf.1","depends_on_id":"xf-9rf","type":"parent-child","created_at":"2026-01-10T02:24:03.909918163-05:00","created_by":"ubuntu"}]}
{"id":"xf-9rf.2","title":"Build architecture map + core workflow understanding","description":"Goal:\n- Produce a high-level architecture map of xf: major modules, data flow, and runtime workflows.\n\nContext:\n- Requires prior understanding of AGENTS.md/README constraints.\n\nSteps:\n1) Inventory key modules in /data/projects/xf/src (main.rs, parser.rs, search.rs, storage.rs, index.rs, etc.).\n2) Trace core flows: indexing path (input archive -\u003e parse -\u003e storage/index), search path (query parse -\u003e execution -\u003e result formatting).\n3) Note data boundaries: DB (SQLite), search index (Tantivy), file I/O paths, and serialization formats.\n4) Record a module graph (imports, public APIs, and cross-module calls).\n\nAcceptance:\n- A concise but complete architecture summary that identifies the main pipeline stages, storage layers, and execution entry points.\n- List of files/functions that are hot paths or correctness-critical.\n","notes":"Architecture map (high level):\n- Entry point: src/main.rs wires CLI (Cli/Commands) to command handlers: index/search/stats/tweet/list/export/config/update/completions.\n- CLI definitions: src/cli.rs declares subcommands + many flags (types/limit/offset/sort/since/until/replies/context/fields, etc.). Some flags are not yet wired in main.rs (noted for later correctness checks).\n- Core modules (src/lib.rs): parser, model, storage (SQLite), search (Tantivy), config/logging/perf/error.\n\nIndexing flow:\n1) xf index \u003carchive\u003e (main.rs cmd_index): validate archive/data/, resolve db/index paths, optionally clear existing data.\n2) ArchiveParser (parser.rs) parses JS-wrapped JSON (window.YTD.*) with rayon; parse_manifest -\u003e ArchiveInfo; parse_tweets/likes/dms/grok/followers/etc into model types.\n3) Storage::open (storage.rs) opens SQLite, sets pragmas, migrates schema, and stores data into normalized tables + FTS5 virtual tables.\n4) SearchEngine::open (search.rs) opens/creates Tantivy index; writer adds documents for each data type (id/text/text_prefix/type/created_at/metadata) and commits.\n\nSearch flow:\n1) xf search \u003cquery\u003e (main.rs cmd_search): open SearchEngine and Storage; map DataType -\u003e search::DocType; call SearchEngine::search with limit+offset.\n2) SearchEngine::search (search.rs) uses Tantivy QueryParser (text + prefix field) and optional type filter; collects TopDocs; builds SearchResult with highlights (snippet generator) and metadata (stored JSON).\n3) main.rs formats results to json/json pretty/csv/compact/text (with highlight -\u003e ANSI conversion in print_result).\n\nData boundaries:\n- Input: archive files under \u003carchive\u003e/data/*.js with JS prefix; parser tolerates whitespace and trailing semicolons.\n- Storage: SQLite schema for tweets/likes/dms/grok + FTS5 tables; metadata in archive_info/meta tables.\n- Search index: Tantivy index under XF_INDEX; schema fields include id, text, text_prefix (prefix matching), type, created_at, metadata.\n\nHot paths / correctness-critical:\n- parser.rs: parse_js_file, parse_* per datatype; date parsing; numeric parsing; message aggregation.\n- search.rs: schema construction, index_* methods, query parsing, snippet generation.\n- storage.rs: schema/migrations + store_* insertions and FTS5 updates.\n","status":"closed","priority":2,"issue_type":"task","assignee":"ubuntu","created_at":"2026-01-10T02:25:50.678053409-05:00","created_by":"ubuntu","updated_at":"2026-01-10T02:27:35.671086605-05:00","closed_at":"2026-01-10T02:27:35.671094189-05:00","dependencies":[{"issue_id":"xf-9rf.2","depends_on_id":"xf-9rf","type":"parent-child","created_at":"2026-01-10T02:25:50.679360841-05:00","created_by":"ubuntu"},{"issue_id":"xf-9rf.2","depends_on_id":"xf-9rf.1","type":"blocks","created_at":"2026-01-10T02:26:00.328123138-05:00","created_by":"ubuntu"}]}
{"id":"xf-9rf.3","title":"Random deep-dive file investigations + flow traces","description":"Goal:\n- Randomly sample code files and deeply trace execution flows through imports/callers to build intuitive understanding beyond the main path.\n\nSteps:\n1) Use rg/rg --files to list candidate files; pick a random subset across modules (parser, search, storage, CLI, tests, benches).\n2) For each file: identify entry points, key data structures, and how its functions are called from other modules.\n3) Trace at least 2 multi-hop flows (file A -\u003e file B -\u003e file C) with notes on inputs/outputs and invariants.\n4) Record any surprising behavior or potential correctness pitfalls discovered during tracing.\n\nAcceptance:\n- At least 5 files deeply analyzed with call/flow notes.\n- Flow traces identify caller/callee relationships and data transformations across module boundaries.\n","notes":"Deep-dive notes (random file sampling + flow traces):\n- src/main.rs: command dispatcher; cmd_index -\u003e ArchiveParser::parse_* -\u003e Storage::store_* + SearchEngine::index_* -\u003e writer.commit + reload. cmd_search -\u003e SearchEngine::search -\u003e output formatting; cmd_stats/tweet/list/export/config/update are stubs/partial (yellow warnings) in main.\n- src/parser.rs: read_data_file -\u003e parse_js_file (split on first '=') -\u003e serde_json Value -\u003e parse_* into model structs. Uses rayon par_iter for JSON arrays. parse_manifest reads manifest.js and normalizes dates/numeric fields.\n- src/search.rs: schema defines id/text/text_prefix/type/created_at/metadata. index_* builds Tantivy docs; search() builds QueryParser over text+text_prefix, optional type filters with BooleanQuery; SnippetGenerator for highlights; SearchResult assembled with metadata JSON.\n- src/storage.rs: opens SQLite with WAL + perf pragmas; migrate/create schema; store_* inserts per model and maintains FTS5 tables; get_tweet/stats queries. Data normalized; DM messages linked by conversation_id.\n- src/cli.rs: defines flags (types, limit/offset/sort, since/until, replies/context/fields). Several flags are not wired in main.rs yet (potential correctness/UX gap for later bug-hunt).\n- src/config.rs/logging.rs/perf.rs/error.rs: full-featured config/logging/perf budgets/custom errors defined but currently not integrated into main.rs (latent functionality).\n- benches/search_perf.rs: synthetic benchmarks invoke SearchEngine and Storage directly; provides baseline for search/index/storage; uses TempDir and synthetic models.\n\nMulti-hop flow traces:\n1) xf index -\u003e main.rs cmd_index -\u003e ArchiveParser::parse_tweets -\u003e model::Tweet -\u003e Storage::store_tweets (SQLite inserts + FTS5) -\u003e SearchEngine::index_tweets (Tantivy doc) -\u003e commit + reload.\n2) xf search -\u003e main.rs cmd_search -\u003e SearchEngine::search -\u003e QueryParser + TopDocs -\u003e SnippetGenerator -\u003e model::SearchResult -\u003e main.rs output formatter (json/csv/text/compact).\n\nPotential pitfalls observed (for later bug review):\n- CLI flags defined but not used (sort/since/until/replies/context/fields/threads etc.).\n- Config/logging/perf modules unused; custom error types largely bypassed by anyhow usage in main.\n","status":"closed","priority":2,"issue_type":"task","assignee":"ubuntu","created_at":"2026-01-10T02:27:54.059223458-05:00","created_by":"ubuntu","updated_at":"2026-01-10T02:29:46.586423572-05:00","closed_at":"2026-01-10T02:29:46.586430315-05:00","dependencies":[{"issue_id":"xf-9rf.3","depends_on_id":"xf-9rf","type":"parent-child","created_at":"2026-01-10T02:27:54.061604543-05:00","created_by":"ubuntu"},{"issue_id":"xf-9rf.3","depends_on_id":"xf-9rf.2","type":"blocks","created_at":"2026-01-10T02:28:02.980609232-05:00","created_by":"ubuntu"}]}
{"id":"xf-9rf.4","title":"Review prior agent changes for correctness and regressions","description":"Goal:\n- Audit code written by other agents (not limited to latest commits) to identify bugs, inefficiencies, or regressions.\n\nSteps:\n1) Use git log/diff to locate code changes authored by agents; scan both recent and older edits.\n2) For each change: verify logic vs requirements; look for edge cases, incorrect assumptions, or performance pitfalls.\n3) Cross-check with tests/benches; add targeted tests if a bug is found.\n4) Record root-cause analysis for any issues discovered.\n\nAcceptance:\n- A documented list of reviewed changes, with issues (if any) and their root causes.\n- Any fixes are minimal, scoped, and comply with AGENTS.md editing rules.\n","notes":"Reviewed uncommitted/agent-origin diffs:\n- src/main.rs: cmd_export implemented (JSON/JSONL/CSV) + csv_escape/format_export helpers; uses Storage::get_all_* and writes to file or stdout. No correctness regressions spotted; minor risk: CSV header order uses serde_json map iteration; should be deterministic for struct field order.\n- src/storage.rs: new get_all_tweets/likes/dms/followers/following; migrate now takes \u0026self; json fields parsed with serde_json::from_str (stored values are always serialized JSON, so NULL risk low). get_all_dms drops conversation_id because DirectMessage model lacks it.\n- src/parser.rs: parse_js_file uses splitn(2,'=') and trims; parse_i64 added for sizeBytes/favorite/retweet counts; doc comments expanded. Behavior aligns with JS wrapper format and should be more tolerant.\n- src/config.rs/logging.rs/error.rs/lib.rs/cli.rs: mostly must_use/const/default/allow annotations and doc tweaks; no functional changes.\n\nPotential concerns (not confirmed bugs):\n- Export of DMs lacks conversation_id context (DirectMessage model does not carry it). If CLI intended to export conversations, model/API may need extension.\n- Several CLI flags remain unimplemented in main.rs (sort/since/until/replies/context/fields). Not introduced by these diffs, but a correctness/UX gap for later bug hunt.\n\nNo immediate regressions found that warrant code changes at this step.\n","status":"closed","priority":2,"issue_type":"task","assignee":"ubuntu","created_at":"2026-01-10T02:30:01.076013082-05:00","created_by":"ubuntu","updated_at":"2026-01-10T02:34:02.360639254-05:00","closed_at":"2026-01-10T02:34:02.360646728-05:00","dependencies":[{"issue_id":"xf-9rf.4","depends_on_id":"xf-9rf","type":"parent-child","created_at":"2026-01-10T02:30:01.078025102-05:00","created_by":"ubuntu"},{"issue_id":"xf-9rf.4","depends_on_id":"xf-9rf.2","type":"blocks","created_at":"2026-01-10T02:30:10.794020969-05:00","created_by":"ubuntu"}]}
{"id":"xf-9rf.5","title":"Fresh-eyes bug hunt + correctness fixes","description":"Goal:\n- Conduct a careful, methodical bug hunt across the codebase and fix issues with minimal, test-backed diffs.\n\nSteps:\n1) Re-read critical paths (parser/search/storage/CLI) with fresh eyes.\n2) Identify obvious errors: unchecked assumptions, incorrect error handling, silent fallbacks.\n3) For each issue: document root cause and impact; add tests before fixing when possible.\n4) Apply minimal fix using apply_patch; no unrelated refactors.\n\nAcceptance:\n- Any fixes include root-cause notes and tests when feasible.\n- No regressions; clippy/fmt/test plan recorded.\n","notes":"Manually applied rustfmt-equivalent changes across benches/tests and src (search.rs, storage.rs, parser.rs, error.rs, config.rs, logging.rs, perf.rs, main.rs). cargo fmt --check now passes. Ran cargo check --all-targets and cargo clippy --all-targets -- -D warnings; both pass.","status":"in_progress","priority":2,"issue_type":"task","assignee":"ubuntu","created_at":"2026-01-10T02:34:40.255520526-05:00","created_by":"ubuntu","updated_at":"2026-01-10T16:23:02.418785018-05:00","dependencies":[{"issue_id":"xf-9rf.5","depends_on_id":"xf-9rf","type":"parent-child","created_at":"2026-01-10T02:34:40.256783946-05:00","created_by":"ubuntu"},{"issue_id":"xf-9rf.5","depends_on_id":"xf-9rf.3","type":"blocks","created_at":"2026-01-10T02:34:50.320708583-05:00","created_by":"ubuntu"}]}
